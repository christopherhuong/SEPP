---
title: "BGGM"
author: "Christopher Huong"
date: "2024-04-29"
output: html_document
---



```{r, message=,warning=F}
library(bootnet)
library(qgraph)
library(MASS)
library(BGGM)
```

Implementing two Bayesian approaches to compare Gaussian graphical models (GGMs) \
From: \
Williams, D. R., Rast, P., Pericchi, L. R., & Mulder, J. (2020). Comparing Gaussian graphical models with the posterior predictive distribution and Bayesian model selection. Psychological methods, 25(5), 653.


Simulate 2 random GGMs

```{r}
nVar=5
nSample = 1e3
set.seed(123)
GGM_0 <- genGGM(nVar, p=0.5, propPositive=0.8)
GGM_1 <- genGGM(nVar, p=0.5, propPositive=0.8)
```


To simulate multivariate Gaussian distributed data, get variance-covariance matrix Sigma by setting diagonal elements=1, reversing the signs of the off-diagonals, taking the inverse, and standardizing. Thus, the GGM is encoded by the precision matrix Theta

```{r}
Sigma0 <- solve(diag(ncol(GGM_0)) - GGM_0) |> cov2cor()
Sigma1 <- solve(diag(ncol(GGM_1)) - GGM_1) |> cov2cor()
```




Check if covariance matrix is positive semi definite
```{r}
eigen(Sigma0)$values >= 0
eigen(Sigma0)$values >= 0
```

Simulate data for control and treatment groups
```{r}
data_0 <- mvrnorm(n=nSample, mu=rep(0, nVar), Sigma=Sigma0) |>
  cbind(rep(0, nSample))

data_1 <- mvrnorm(n=nSample, mu=rep(0, nVar), Sigma=Sigma1) |>
  cbind(rep(1, nSample))

data <- rbind(data_0, data_1) |> as.data.frame()
```

Estimate GGM on all data, and GGMs for each condition using lasso regularization with lambda selected by minimizing the EBIC, with hyperparameter gamma set to 0.5

```{r}
ggm_fit_all <- estimateNetwork(data=data[, 1:nVar], default="EBICglasso", tuning=0.5)
ggm_fit_0 <- estimateNetwork(data=data[data$V6==0, 1:nVar], default="EBICglasso", tuning=0.5)
ggm_fit_1 <- estimateNetwork(data=data[data$V6==1, 1:nVar], default="EBICglasso", tuning=0.5)
ggm_list <- list(ggm_all=ggm_fit_all, ggm_0=ggm_fit_0, ggm_1=ggm_fit_1)

```

Plot

```{r}
par(mfrow=c(3,1))
for(v in 1:3){
  qgraph(ggm_list[[v]]$graph, title=names(ggm_list[v]))
}

```


To compare GGMs, we compute the posterior probability of Theta conditioning on the observed data and null model (i.e., data in each group are generated by the same multivariate Gaussian distribution): \

P(Theta | Y[obs], M[0]) \
Theta ~ W(n - 1, S^-1) \


Where Theta is the common precision matrix, Y[obs] is the n x p data matrix of n observed responses for p persons, and M[0] is the null model. The improper Jeffreys prior distribution is used, where















